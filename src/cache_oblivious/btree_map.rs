use std::borrow::Borrow;
use std::collections::VecDeque;
use std::convert::TryInto;
use std::fmt::{self, Debug};
use std::ops::Range;
use std::sync::atomic::Ordering;
use std::sync::{Arc, RwLock};

use num_rational::{Ratio, Rational};

use super::cell::{Cell, CellGuard, CellIterator, Key, Marker};
use super::packed_memory_array::PackedMemoryArray;

/// Result of a rebalance operation, indicating which blocks (leaves) were affected.
/// This enables incremental index updates instead of full O(N) rebuilds.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct RebalanceResult {
    /// The range of block indices (leaf indices) that were affected by the rebalance.
    /// These blocks may have had their minimum key changed due to cells moving.
    /// An empty range indicates no blocks were affected.
    pub affected_blocks: Range<usize>,
}

impl RebalanceResult {
    /// Creates a new RebalanceResult with the given affected block range.
    pub fn new(affected_blocks: Range<usize>) -> Self {
        RebalanceResult { affected_blocks }
    }

    /// Creates a RebalanceResult indicating no blocks were affected.
    pub fn none() -> Self {
        RebalanceResult {
            affected_blocks: 0..0,
        }
    }

    /// Returns true if any blocks were affected by the rebalance.
    pub fn has_affected_blocks(&self) -> bool {
        !self.affected_blocks.is_empty()
    }
}

pub struct BTreeMap<K: Clone + Ord, V: Clone> {
    data: Arc<PackedMemoryArray<Cell<K, V>>>,
    index: Arc<RwLock<BlockIndex<K, V>>>,
}

impl<K, V> BTreeMap<K, V>
where
    K: 'static + Clone + Ord,
    V: 'static + Clone,
{
    pub fn new(capacity: usize) -> BTreeMap<K, V> {
        let packed_cells = PackedMemoryArray::with_capacity(capacity);
        let data = Arc::new(packed_cells);

        let raw_index = Self::generate_index(Arc::clone(&data));
        let index = Arc::new(RwLock::new(raw_index));

        BTreeMap { index, data }
    }

    pub fn get<Q>(&self, key: &Q) -> Option<V>
    where
        Q: Ord,
        K: Borrow<Q>,
    {
        self.index.read().unwrap().get(key)
    }

    pub fn insert<'a>(&'a mut self, key: K, value: V)
    where
        K: Debug,
    {
        // Collect affected blocks from rebalance operations
        let mut affected_blocks: Vec<Range<usize>> = Vec::new();
        let mut inserted_cell_ptr: Option<*const Cell<K, V>> = None;

        {
            let index = self.index.read().unwrap();
            let (block, min_key) = match index.get_block_for_insert(&key) {
                SearchResult::Block(block, min_key) => (block, min_key),
                _ => panic!("No block found for insert of key {:?}", key),
            };

            let iter = CellIterator::new(block.cell_slice_ptr, self.data.active_range.end);

            let mut selected_cell: Option<CellGuard<K, V>> = None;
            for mut cell_guard in iter {
                if cell_guard.is_empty() {
                    // node says there's a cell smaller than ours, keep looking
                    if selected_cell.is_none() && min_key <= Key::Value(&key) {
                        continue;
                    // block is empty
                    } else {
                        selected_cell = None;
                    }
                } else {
                    let cache = cell_guard.cache().unwrap().clone().unwrap();
                    if Key::Value(&cache.key) < Key::Value(&key) {
                        selected_cell = Some(cell_guard);
                        continue;
                    } else if Key::Value(&cache.key) == Key::Value(&key) {
                        selected_cell = None;
                    } else if selected_cell.is_none() {
                        // we didn't find any cells that were <= our key, rebalance to make room
                        // is_smallest_key = true;
                        let result = self.rebalance(cell_guard.inner as *const _, true);
                        if result.has_affected_blocks() {
                            affected_blocks.push(result.affected_blocks);
                        }
                    }
                }

                if let Some(cell_to_move) = &selected_cell {
                    // move cell to make room for insert
                    let result = self.rebalance(cell_to_move.inner, true);
                    if result.has_affected_blocks() {
                        affected_blocks.push(result.affected_blocks);
                    }
                }

                let marker_version = cell_guard.cache_version + 1;
                let cell = selected_cell.as_mut().unwrap_or(&mut cell_guard);

                let marker = Marker::InsertCell(marker_version, key.clone(), value.clone());

                let result = cell.update(marker);

                if result.is_err() {
                    // Marker has been updated by another process, start loop over
                    continue;
                }

                let prev_marker = result.unwrap();

                // We now have exclusive access to the cell until we update `version`.
                // This works well for mutating through UnsafeCell<T>, but isn't really
                // "lock-free"...
                unsafe {
                    cell.inner.key.get().write(Some(key));
                    cell.inner.value.get().write(Some(value));
                };

                // Track the cell where we inserted for index update
                inserted_cell_ptr = Some(cell.inner as *const Cell<K, V>);

                let next_version = marker_version + 1;

                // Reuse previous marker allocation
                unsafe { prev_marker.write(Marker::Empty(next_version)) };
                cell.inner
                    .marker
                    .as_ref()
                    .unwrap()
                    .swap(prev_marker, Ordering::SeqCst);
                cell.inner.version.swap(next_version, Ordering::SeqCst);

                break;
            }
        } // Read lock on index is dropped here

        // Update the index for affected blocks
        self.update_index_for_affected_blocks(&affected_blocks, inserted_cell_ptr);
    }

    /// Updates the index for blocks affected by rebalance operations and the insertion.
    ///
    /// For cache-oblivious efficiency, blocks are updated in sorted order (by leaf index)
    /// to maximize memory locality when accessing the vEB-layout tree.
    fn update_index_for_affected_blocks(
        &mut self,
        affected_blocks: &[Range<usize>],
        inserted_cell_ptr: Option<*const Cell<K, V>>,
    ) {
        // Collect affected block indices into a sorted vector for cache-friendly access
        let mut blocks_to_update: Vec<usize> = Vec::new();

        for range in affected_blocks {
            for block_idx in range.clone() {
                blocks_to_update.push(block_idx);
            }
        }

        // Also update the block where we inserted
        if let Some(ptr) = inserted_cell_ptr {
            if let Some(block_idx) = self.cell_ptr_to_block_index(ptr) {
                blocks_to_update.push(block_idx);
            }
        }

        // Skip if no blocks to update
        if blocks_to_update.is_empty() {
            return;
        }

        // Sort and deduplicate leaf indices for cache-friendly sequential access.
        // Note: We're sorting logical leaf indices (0, 1, 2, ...), not moving any cells
        // or nodes. The leaf_positions array in BlockSearchTree maps these indices to
        // actual node positions in the vEB layout. Sorting ensures we access the PMA
        // in sequential order when computing min_keys, maximizing cache locality.
        blocks_to_update.sort_unstable();
        blocks_to_update.dedup();

        // Acquire write lock and update each affected block in sorted order
        let mut index = self.index.write().unwrap();
        for block_idx in blocks_to_update {
            let new_min_key = index.compute_block_min_key(block_idx);
            index.update_leaf(block_idx, new_min_key);
        }
    }

    pub fn generate_index(data: Arc<PackedMemoryArray<Cell<K, V>>>) -> BlockIndex<K, V> {
        BlockIndex {
            map: Arc::clone(&data),
            index_tree: BlockSearchTree::new(data),
        }
    }

    fn rebalance(&self, cell_ptr_start: *const Cell<K, V>, for_insertion: bool) -> RebalanceResult {
        let mut count = 1;
        let mut cells_to_move: VecDeque<*const Cell<K, V>> = VecDeque::new();
        let mut current_cell_ptr = cell_ptr_start;

        // Track the range of cells affected for computing block indices
        let mut last_cell_ptr = cell_ptr_start;

        let iter = CellIterator::new(cell_ptr_start, self.data.active_range.end);

        for cell_guard in iter {
            current_cell_ptr = cell_guard.inner;
            last_cell_ptr = cell_guard.inner;

            if !cell_guard.is_empty() {
                cells_to_move.push_front(cell_guard.inner);
            }

            let numer = if for_insertion {
                cells_to_move.len() + 1
            } else {
                cells_to_move.len()
            };

            let current_density =
                Rational::new(numer.try_into().unwrap(), count.try_into().unwrap());

            if self.within_density_threshold(count, current_density) {
                break;
            }

            count += 1;
        }

        // There are different strategies available for rebalancing
        // depending on the inserts expected in the system.
        //
        // To support many inserts in the same area, we want to shift
        // elements as far right as possible, while still maintaining
        // our density thresholds. Since we know we needed exactly
        // this # of cells to meet our density, one less than this
        // should let each region maximize their respective thresholds.

        // Starting at current_marker_raw, move the cells rightward
        // until their max density is reached

        // TODO: Can we use #compare_and_swap for neighbouring cells
        // to make sure we don't leave any cells unallocated?

        for cell_ptr in cells_to_move.iter() {
            let cell = unsafe { &*current_cell_ptr };
            let cell_key = unsafe { &*cell.key.get() };
            if cell_key.is_some() {
                // TODO: I think we can overwrite these records since their contents have been moved...
            }

            let cell_to_move = unsafe { &**cell_ptr };
            let version = cell_to_move.version.load(Ordering::SeqCst);
            let current_marker_raw = cell_to_move.marker.as_ref().unwrap().load(Ordering::SeqCst);
            let marker = unsafe { &*current_marker_raw };
            let marker_version = *marker.version();

            if version != marker_version {
                todo!("Restart rebalance!");
            }

            // todo: self.data.into_iter() seems suspicious here
            let dest_index = unsafe {
                current_cell_ptr
                    .offset_from(self.data.into_iter().next().unwrap() as *const Cell<K, V>)
            };
            let new_marker = Box::new(Marker::Move(marker_version, dest_index));

            let new_marker_raw = Box::into_raw(new_marker);
            let prev_marker = cell_to_move.marker.as_ref().unwrap().compare_exchange(
                current_marker_raw,
                new_marker_raw,
                Ordering::SeqCst,
                Ordering::SeqCst,
            );

            if prev_marker.is_err() {
                // Marker has been updated by another process.
                // Deallocate memory, start loop over.
                unsafe { drop(Box::from_raw(new_marker_raw)) };
                todo!("Restart rebalance!");
            }

            unsafe {
                // update new cell
                cell.key.get().write((*cell_to_move.key.get()).clone());
                cell.value.get().write((*cell_to_move.value.get()).clone());
                // todo update version and marker of new cell?

                // update old cell
                cell_to_move.key.get().write(None);
                cell_to_move.value.get().write(None);
                let new_version = version + 1;
                // reuse prev_marker box
                prev_marker.unwrap().write(Marker::Empty(new_version));
                // use compare_exchange_weak because we can safely fail here
                let _ = cell_to_move.marker.as_ref().unwrap().compare_exchange_weak(
                    new_marker_raw,
                    prev_marker.unwrap(),
                    Ordering::SeqCst,
                    Ordering::SeqCst,
                );
                let _ = cell_to_move.version.compare_exchange_weak(
                    marker_version,
                    new_version,
                    Ordering::SeqCst,
                    Ordering::SeqCst,
                );
                // TODO: increment version, clear marker
            };

            current_cell_ptr = unsafe { current_cell_ptr.sub(1) };
            if self.data.is_valid_pointer(&current_cell_ptr) {
                continue;
            } else {
                unreachable!("We've reached the end of the initialized cell buffer!");
            }
        }

        // Compute the affected block range
        // Cells move from first_cell_ptr toward current_cell_ptr (which moved backward)
        // The affected range spans from the destination (current_cell_ptr moved back)
        // to the source area (first_cell_ptr through last_cell_ptr)
        self.compute_affected_blocks(current_cell_ptr, last_cell_ptr)
    }

    /// Computes the block index (leaf index) for a given cell pointer.
    ///
    /// Block index is determined by: cell_offset / slot_size
    /// where slot_size = log2(requested_capacity)
    ///
    /// Returns None if the pointer is outside the active range.
    fn cell_ptr_to_block_index(&self, cell_ptr: *const Cell<K, V>) -> Option<usize> {
        let base_ptr = self.data.as_slice().as_ptr();
        let slice_len = self.data.as_slice().len();

        // Check bounds
        let offset = unsafe { cell_ptr.offset_from(base_ptr) };
        if offset < 0 || offset as usize >= slice_len {
            return None;
        }

        let cell_offset = offset as usize;
        let slot_size = self.data.requested_capacity.ilog2() as usize;
        Some(cell_offset / slot_size)
    }

    /// Computes the range of blocks affected by a rebalance operation.
    ///
    /// The affected range includes all blocks from the destination area
    /// (where cells were moved to) through the source area (where cells came from).
    fn compute_affected_blocks(
        &self,
        dest_ptr: *const Cell<K, V>,
        source_end_ptr: *const Cell<K, V>,
    ) -> RebalanceResult {
        // Get block indices for the range boundaries
        let dest_block = self.cell_ptr_to_block_index(dest_ptr);
        let source_block = self.cell_ptr_to_block_index(source_end_ptr);

        match (dest_block, source_block) {
            (Some(start), Some(end)) => {
                // Range is from dest (lower address) to source (higher address)
                // Add 1 to end because Range is exclusive
                let (lo, hi) = if start <= end {
                    (start, end + 1)
                } else {
                    (end, start + 1)
                };
                RebalanceResult::new(lo..hi)
            }
            _ => RebalanceResult::none(),
        }
    }

    fn within_density_threshold(&self, num_items: usize, current_density: Ratio<isize>) -> bool {
        let density = self
            .data
            .config
            .density_scale
            .iter()
            .find(|d| d.max_item_count >= num_items)
            .unwrap();

        density.range.contains(&current_density)
    }
}

impl<K, V> Debug for BTreeMap<K, V>
where
    K: Copy + Ord + Debug,
    V: Clone + Debug,
{
    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {
        formatter
            .debug_struct("BTreeMap")
            .field("data", &format_args!("{:?}", self.data))
            .finish()
    }
}

pub struct BlockIndex<K: Clone + Ord, V: Clone> {
    map: Arc<PackedMemoryArray<Cell<K, V>>>,
    index_tree: BlockSearchTree<K, V>,
}

unsafe impl<K: Clone + Ord, V: Clone> Send for BlockIndex<K, V> {}
unsafe impl<K: Clone + Ord, V: Clone> Sync for BlockIndex<K, V> {}

impl<K, V> Debug for BlockIndex<K, V>
where
    K: Clone + Ord + Debug,
    V: Clone + Debug,
{
    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {
        formatter
            .debug_struct("BlockIndex")
            .field("map", &format_args!("{:?}", self.map))
            .field("index_tree", &format_args!("{:?}", self.index_tree))
            .finish()
    }
}

impl<K, V> BlockIndex<K, V>
where
    K: Clone + Ord,
    V: Clone,
{
    fn get_block_for_insert<'a, Q>(&'a self, search_key: &Q) -> SearchResult<'a, K, V>
    where
        Q: Ord,
        K: Borrow<Q>,
    {
        self.index_tree.find(search_key, true)
    }

    pub fn get<Q>(&self, search_key: &Q) -> Option<V>
    where
        Q: Ord,
        K: Borrow<Q>,
    {
        match self.index_tree.find(search_key, false) {
            SearchResult::NotFound => return None,
            SearchResult::Block(block, ..) => {
                let iter = CellIterator::new(block.cell_slice_ptr, self.map.active_range.end);

                for cell_guard in iter {
                    if !cell_guard.is_empty() {
                        let cache = cell_guard.cache().unwrap().clone().unwrap();
                        let cache_key = cache.key.borrow();
                        if cache_key == search_key {
                            return Some(cache.value);
                        } else if cache_key > search_key {
                            return None;
                        }
                    }
                }

                None
            }
        }
    }

    /// Updates a leaf's min_key for incremental index maintenance.
    ///
    /// # Arguments
    /// * `leaf_index` - The leaf index (0..num_leaves) to update
    /// * `new_min_key` - The new minimum key for this leaf
    ///
    /// # Returns
    /// `true` if the update was successful, `false` if leaf_index is out of bounds.
    fn update_leaf(&mut self, leaf_index: usize, new_min_key: Key<K>) -> bool {
        self.index_tree.update_leaf(leaf_index, new_min_key)
    }

    /// Returns the slot size (number of cells per block/leaf).
    fn slot_size(&self) -> usize {
        self.map.requested_capacity.ilog2() as usize
    }

    /// Computes the minimum key for a given block index.
    ///
    /// Reads the cells in the block and returns the key of the first non-empty cell,
    /// or Key::Supremum if all cells are empty.
    fn compute_block_min_key(&self, block_index: usize) -> Key<K> {
        let slot_size = self.slot_size();
        let start_offset = block_index * slot_size;
        let cells = self.map.as_slice();

        // Check bounds
        if start_offset >= cells.len() {
            return Key::Supremum;
        }

        let end_offset = (start_offset + slot_size).min(cells.len());
        let block_cells = &cells[start_offset..end_offset];

        // Find the first non-empty cell (cells are sorted within a block)
        for cell in block_cells {
            let key_opt = unsafe { (*cell.key.get()).as_ref() };
            if let Some(k) = key_opt {
                return Key::Value(k.clone());
            }
        }

        Key::Supremum
    }
}

struct BlockSearchTree<K: Clone + Ord, V: Clone> {
    nodes: Box<[Node<K, V>]>,
    /// Precomputed subtree sizes for vEB layout navigation.
    /// Each entry stores (upper_subtree_size, lower_subtree_size) at each vEB recursion level.
    /// This enables O(log log N) child position computation without explicit pointers.
    subtree_sizes: Box<[SubtreeSizes]>,
    /// Height of the tree (number of levels from root to leaves).
    height: u8,
    /// Precomputed leaf positions in left-to-right order (in-order traversal).
    /// Maps leaf_index (0..num_leaves) to node array position.
    /// Enables O(1) leaf-to-position lookup for incremental updates.
    leaf_positions: Box<[usize]>,
}

/// Stores the sizes of upper and lower subtrees at a given vEB recursion level.
/// Used for implicit child navigation in the vEB layout.
#[derive(Debug, Clone, Copy)]
struct SubtreeSizes {
    /// Number of nodes in the upper subtree (including root of that level).
    upper_size: usize,
    /// Number of nodes in each lower subtree.
    lower_size: usize,
}

/// Tracks navigation state within the vEB-layout tree.
/// This enables implicit child position computation without explicit pointers.
#[derive(Debug, Clone, Copy)]
struct VebNavigator {
    /// Current position in the flattened node array.
    position: usize,
    /// Base offset of the current vEB subtree in the node array.
    subtree_base: usize,
    /// Current depth within the vEB recursion (index into subtree_sizes).
    veb_depth: usize,
    /// Position within the current upper subtree (0-indexed from subtree's root).
    local_position: usize,
    /// Size of the current subtree (used for bounds checking at deepest level).
    current_subtree_size: usize,
}

impl VebNavigator {
    /// Creates a navigator starting at the root of the tree.
    fn at_root(tree_size: usize) -> Self {
        VebNavigator {
            position: 0,
            subtree_base: 0,
            veb_depth: 0,
            local_position: 0,
            current_subtree_size: tree_size,
        }
    }

    /// Computes the position of the left child and returns a new navigator for it.
    ///
    /// # Arguments
    /// * `subtree_sizes` - The precomputed subtree sizes for vEB navigation
    ///
    /// # Returns
    /// A new `VebNavigator` pointing to the left child position.
    fn left_child(&self, subtree_sizes: &[SubtreeSizes]) -> VebNavigator {
        self.child(subtree_sizes, false)
    }

    /// Computes the position of the right child and returns a new navigator for it.
    ///
    /// # Arguments
    /// * `subtree_sizes` - The precomputed subtree sizes for vEB navigation
    ///
    /// # Returns
    /// A new `VebNavigator` pointing to the right child position.
    fn right_child(&self, subtree_sizes: &[SubtreeSizes]) -> VebNavigator {
        self.child(subtree_sizes, true)
    }

    /// Checks if the current position is valid (within the bounds of its subtree).
    /// This should be called after navigating to check if the resulting position
    /// actually exists in the tree.
    fn is_valid(&self) -> bool {
        self.local_position < self.current_subtree_size
    }

    /// Computes child position within the vEB layout.
    ///
    /// The vEB layout organizes nodes as:
    /// 1. Upper subtree nodes are stored first (contiguously)
    /// 2. Lower subtrees follow, in order of their parent leaves in the upper subtree
    ///
    /// Within the upper subtree, standard binary tree indexing applies:
    /// - Left child of node at local position `p` is at `2*p + 1`
    /// - Right child of node at local position `p` is at `2*p + 2`
    ///
    /// When transitioning from upper to lower subtree:
    /// - We jump past the upper subtree
    /// - Then index into the correct lower subtree based on which leaf we came from
    fn child(&self, subtree_sizes: &[SubtreeSizes], is_right: bool) -> VebNavigator {
        if self.veb_depth >= subtree_sizes.len() {
            // At the deepest vEB level, use simple binary tree arithmetic
            // within the current subtree bounds
            let child_local = if is_right {
                2 * self.local_position + 2
            } else {
                2 * self.local_position + 1
            };

            return VebNavigator {
                position: self.subtree_base + child_local,
                subtree_base: self.subtree_base,
                veb_depth: self.veb_depth,
                local_position: child_local,
                current_subtree_size: self.current_subtree_size,
            };
        }

        let sizes = &subtree_sizes[self.veb_depth];
        let upper_size = sizes.upper_size;
        let lower_size = sizes.lower_size;

        // Child position in standard binary tree indexing within upper subtree
        let child_local = if is_right {
            2 * self.local_position + 2
        } else {
            2 * self.local_position + 1
        };

        if child_local < upper_size {
            // Child is still within the upper subtree
            VebNavigator {
                position: self.subtree_base + child_local,
                subtree_base: self.subtree_base,
                veb_depth: self.veb_depth,
                local_position: child_local,
                current_subtree_size: self.current_subtree_size,
            }
        } else {
            // Child transitions to a lower subtree
            // Compute which lower subtree (based on leaf index in upper subtree)
            // In a complete binary tree, leaves are at positions [n/2, n-1] where n = size
            // The leaf index (0-indexed) is: child_local - upper_size
            let leaf_index = child_local - upper_size;

            // Lower subtrees are stored after the upper subtree, each of size lower_size
            let lower_subtree_base = self.subtree_base + upper_size + leaf_index * lower_size;

            VebNavigator {
                position: lower_subtree_base,
                subtree_base: lower_subtree_base,
                veb_depth: self.veb_depth + 1,
                local_position: 0,
                current_subtree_size: lower_size,
            }
        }
    }
}

/// Precomputes subtree sizes at each vEB recursion level for a tree of the given height.
///
/// The vEB layout recursively splits a tree of height h into:
/// - An "upper" subtree of height ceil(h/2) containing the top portion
/// - Multiple "lower" subtrees of height floor(h/2) hanging off the upper leaves
///
/// This function returns the sizes at each recursion level, enabling O(1) child
/// position computation during navigation without explicit pointers.
///
/// # Arguments
/// * `total_height` - The height of the complete binary tree (levels from root to leaves)
///
/// # Returns
/// A boxed slice where each entry contains (upper_size, lower_size) for that vEB level.
/// The slice has O(log log N) entries since each recursion roughly halves the height.
fn precompute_subtree_sizes(total_height: u8) -> Box<[SubtreeSizes]> {
    if total_height == 0 {
        return Box::new([]);
    }

    let mut sizes = Vec::new();
    let mut h = total_height as usize;

    while h > 1 {
        // Split: upper gets ceil(h/2), lower gets floor(h/2)
        // For vEB, we want the lower height to be a power of 2 when possible
        let lower_h = if h.is_power_of_two() {
            h / 2
        } else {
            // Round lower_h down to nearest power of 2 for cache-oblivious properties
            (h / 2).next_power_of_two() / 2
        }
        .max(1);
        let upper_h = h - lower_h;

        // Size of a complete binary tree of height h is (2^h - 1) nodes
        let upper_size = (1usize << upper_h) - 1;
        let lower_size = (1usize << lower_h) - 1;

        sizes.push(SubtreeSizes {
            upper_size,
            lower_size,
        });
        h = lower_h;
    }

    sizes.into_boxed_slice()
}

/// Computes the height of a complete binary tree with the given number of nodes.
/// Height is defined as the number of levels (a single node has height 1).
fn compute_tree_height(node_count: usize) -> u8 {
    if node_count == 0 {
        return 0;
    }
    // For a complete binary tree with n nodes: height = floor(log2(n + 1))
    // Since node_count = 2^h - 1 for a full tree, h = log2(node_count + 1)
    ((node_count + 1).ilog2()) as u8
}

impl<'a, K, V> BlockSearchTree<K, V>
where
    K: Clone + Ord,
    V: Clone,
{
    fn new(cells: Arc<PackedMemoryArray<Cell<K, V>>>) -> BlockSearchTree<K, V> {
        let slot_size = cells.requested_capacity.ilog2() as usize;
        let leaf_count = cells.len() / slot_size;
        let node_count = 2 * leaf_count - 1;
        let height = compute_tree_height(node_count);
        let subtree_sizes = precompute_subtree_sizes(height);

        // Precompute leaf positions for O(1) leaf-to-position mapping
        let leaf_positions = Self::collect_leaf_positions_inorder(node_count, &subtree_sizes);

        // Allocate all nodes as Internal initially
        let mut nodes: Vec<Node<K, V>> = (0..node_count)
            .map(|_| Node::Internal {
                min_rhs: Key::Supremum,
            })
            .collect();

        // Use VebNavigator to find all leaf positions and finalize them
        let mut slots = cells.as_slice().chunks_exact(slot_size);
        Self::finalize_leaves_veb(&mut nodes, &subtree_sizes, &mut slots);

        BlockSearchTree {
            nodes: nodes.into_boxed_slice(),
            subtree_sizes,
            height,
            leaf_positions: leaf_positions.into_boxed_slice(),
        }
    }

    /// Recursively traverse the tree using vEB navigation to find and finalize all leaves.
    /// Leaves are visited in left-to-right order (in-order traversal).
    fn finalize_leaves_veb<'b, I>(
        nodes: &mut [Node<K, V>],
        subtree_sizes: &[SubtreeSizes],
        slots: &mut I,
    ) where
        I: Iterator<Item = &'b [Cell<K, V>]>,
        K: 'b,
        V: 'b,
    {
        let node_count = nodes.len();
        if node_count == 0 {
            return;
        }

        // Collect leaf positions in left-to-right order using in-order traversal
        let leaf_positions = Self::collect_leaf_positions_inorder(node_count, subtree_sizes);

        // Finalize leaves in order
        for pos in leaf_positions {
            if let Some(leaf_mem) = slots.next() {
                Self::finalize_leaf_node(&mut nodes[pos], leaf_mem);
            }
        }
    }

    /// Collects all leaf positions in left-to-right (in-order) order.
    fn collect_leaf_positions_inorder(
        node_count: usize,
        subtree_sizes: &[SubtreeSizes],
    ) -> Vec<usize> {
        let mut leaves = Vec::new();
        Self::inorder_collect_leaves(
            VebNavigator::at_root(node_count),
            subtree_sizes,
            &mut leaves,
        );
        leaves
    }

    /// Recursive helper for in-order leaf collection.
    fn inorder_collect_leaves(
        nav: VebNavigator,
        subtree_sizes: &[SubtreeSizes],
        leaves: &mut Vec<usize>,
    ) {
        if !nav.is_valid() {
            return;
        }

        let left = nav.left_child(subtree_sizes);
        let right = nav.right_child(subtree_sizes);

        // Check if this is a leaf (both children are invalid)
        if !left.is_valid() && !right.is_valid() {
            leaves.push(nav.position);
            return;
        }

        // In-order: left, then current (but internal nodes don't contribute), then right
        Self::inorder_collect_leaves(left, subtree_sizes, leaves);
        Self::inorder_collect_leaves(right, subtree_sizes, leaves);
    }

    fn finalize_leaf_node<'b>(leaf: &mut Node<K, V>, leaf_mem: &'b [Cell<K, V>]) {
        match leaf {
            Node::Internal { .. } => {
                let min_key = leaf_mem
                    .first()
                    .and_then(|c| unsafe { (*c.key.get()).as_ref() })
                    .and_then(|k| Some(Key::Value(k.clone())))
                    .unwrap_or(Key::Supremum);

                let length = leaf_mem.len();
                let ptr = leaf_mem as *const [Cell<K, V>] as *const Cell<K, V>;
                let block = Block {
                    cell_slice_ptr: ptr,
                    length,
                };
                *leaf = Node::Leaf(min_key, block);
            }
            Node::Leaf(_, _) => (),
        };
    }

    /// Creates a navigator starting at the root of the tree.
    fn root_navigator(&self) -> VebNavigator {
        VebNavigator::at_root(self.nodes.len())
    }

    /// Gets the node at the given navigator position.
    fn node_at(&'a self, nav: &VebNavigator) -> &'a Node<K, V> {
        &self.nodes[nav.position]
    }

    /// Computes the left child position using implicit vEB navigation.
    fn left_child(&self, nav: &VebNavigator) -> VebNavigator {
        nav.left_child(&self.subtree_sizes)
    }

    /// Computes the right child position using implicit vEB navigation.
    fn right_child(&self, nav: &VebNavigator) -> VebNavigator {
        nav.right_child(&self.subtree_sizes)
    }

    /// Search for a block using implicit vEB navigation.
    fn find<Q>(&'a self, search_key: &Q, for_insertion: bool) -> SearchResult<'a, K, V>
    where
        K: Borrow<Q>,
        Q: Ord,
    {
        let key = Key::Value(search_key);
        let mut nav = self.root_navigator();

        loop {
            let node = self.node_at(&nav);
            match node {
                Node::Leaf(key_lock, block) => {
                    if !for_insertion && *key_lock == Key::Supremum {
                        return SearchResult::NotFound;
                    } else {
                        return SearchResult::Block(block, Key::from(key_lock));
                    }
                }
                Node::Internal { min_rhs } => {
                    nav = if min_rhs.is_supremum()
                        || key < Key::Value(min_rhs.clone().unwrap().borrow())
                    {
                        self.left_child(&nav)
                    } else {
                        self.right_child(&nav)
                    };
                }
            }
        }
    }

    /// Returns the number of leaves in the tree.
    fn leaf_count(&self) -> usize {
        self.leaf_positions.len()
    }

    /// Maps a leaf index (0..num_leaves) to its position in the node array.
    /// Returns None if the leaf_index is out of bounds.
    fn leaf_index_to_position(&self, leaf_index: usize) -> Option<usize> {
        self.leaf_positions.get(leaf_index).copied()
    }

    /// Updates a single leaf's min_key after PMA rebalancing.
    ///
    /// This enables incremental index updates instead of full rebuilds.
    /// After updating the leaf, optionally propagates key changes up to ancestors
    /// if the leaf is the minimum of a right subtree (affects parent's min_rhs).
    ///
    /// # Arguments
    /// * `leaf_index` - The leaf index (0..num_leaves) to update
    /// * `new_min_key` - The new minimum key for this leaf
    ///
    /// # Returns
    /// `true` if the update was successful, `false` if leaf_index is out of bounds.
    fn update_leaf(&mut self, leaf_index: usize, new_min_key: Key<K>) -> bool {
        let pos = match self.leaf_index_to_position(leaf_index) {
            Some(p) => p,
            None => return false,
        };

        // Update the leaf's min_key
        if let Node::Leaf(ref mut min_key, _) = self.nodes[pos] {
            *min_key = new_min_key.clone();
        } else {
            // Position doesn't contain a leaf (shouldn't happen with valid leaf_index)
            return false;
        }

        // Propagate key changes up to ancestors if needed
        self.propagate_key_change(pos, &new_min_key);

        true
    }

    /// Propagates key changes up to ancestors after a leaf update.
    ///
    /// When a leaf's min_key changes, internal nodes storing `min_rhs` may need updates.
    /// An internal node's `min_rhs` represents the minimum key in its right subtree.
    /// If the updated leaf is the leftmost leaf of some node's right subtree,
    /// that node's `min_rhs` must be updated.
    ///
    /// This walks from root to the leaf, updating `min_rhs` for any internal node
    /// where we descend into the right child (meaning the leaf is in the right subtree).
    fn propagate_key_change(&mut self, leaf_pos: usize, new_key: &Key<K>) {
        let mut nav = self.root_navigator();
        let mut path: Vec<(usize, bool)> = Vec::new(); // (position, went_right)

        // Walk from root to the target leaf, recording the path
        loop {
            if nav.position == leaf_pos {
                break;
            }

            match &self.nodes[nav.position] {
                Node::Leaf(_, _) => {
                    // Reached a different leaf, shouldn't happen
                    break;
                }
                Node::Internal { min_rhs } => {
                    // Determine which way to go based on comparing new_key with min_rhs
                    let go_right = !min_rhs.is_supremum() && new_key >= min_rhs;
                    path.push((nav.position, go_right));

                    nav = if go_right {
                        self.right_child(&nav)
                    } else {
                        self.left_child(&nav)
                    };
                }
            }
        }

        // Now update min_rhs for ancestors where we went right AND this is the leftmost
        // leaf in that right subtree.
        // We need to find where the updated leaf is the minimum of the right subtree.
        // This happens when we go right, then only left from that point to the leaf.

        // Work backwards through the path to find the deepest "went_right" followed by only "went_left"
        let mut all_left_from_here = true;
        for (pos, went_right) in path.into_iter().rev() {
            if *&went_right {
                if all_left_from_here {
                    // This node's min_rhs should be updated since the leaf is
                    // the leftmost leaf in its right subtree
                    if let Node::Internal { ref mut min_rhs } = self.nodes[pos] {
                        *min_rhs = new_key.clone();
                    }
                }
                // Once we hit a right turn, stop updating (nodes above this
                // have the leaf in a deeper right subtree, not as their direct min_rhs)
                all_left_from_here = false;
            }
            // If went_left, all_left_from_here stays true
        }
    }
}

impl<K, V> Debug for BlockSearchTree<K, V>
where
    K: Ord + Clone + Debug,
    V: Clone + Debug,
{
    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {
        formatter
            .debug_struct("BlockSearchTree")
            .field("nodes", &format_args!("{:?}", self.nodes))
            .finish()
    }
}

enum Node<K: Clone + Ord, V: Clone> {
    Leaf(Key<K>, Block<K, V>),
    Internal { min_rhs: Key<K> },
}

impl<K, V> Debug for Node<K, V>
where
    K: Ord + Clone + Debug,
    V: Clone + Debug,
{
    fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Node::Leaf(key, ..) => formatter
                .debug_struct("Node::Leaf")
                .field("key", &format_args!("{:?}", key))
                .finish(),
            Node::Internal { min_rhs, .. } => formatter
                .debug_struct("Node::Internal")
                .field("min_rhs", &format_args!("{:?}", min_rhs))
                .finish(),
        }
    }
}

enum SearchResult<'a, K: Clone + Ord, V: Clone> {
    Block(&'a Block<K, V>, Key<&'a K>),
    NotFound,
}

struct Block<K: Clone, V: Clone> {
    cell_slice_ptr: *const Cell<K, V>,
    length: usize,
}

unsafe impl<K: Clone, V: Clone> Send for Block<K, V> {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compute_tree_height() {
        // Height 0 for empty tree
        assert_eq!(compute_tree_height(0), 0);

        // Height 1 for single node
        assert_eq!(compute_tree_height(1), 1);

        // Height 2 for 3 nodes (complete binary tree: 2^2 - 1 = 3)
        assert_eq!(compute_tree_height(3), 2);

        // Height 3 for 7 nodes (complete binary tree: 2^3 - 1 = 7)
        assert_eq!(compute_tree_height(7), 3);

        // Height 4 for 15 nodes (complete binary tree: 2^4 - 1 = 15)
        assert_eq!(compute_tree_height(15), 4);

        // Height 5 for 31 nodes (complete binary tree: 2^5 - 1 = 31)
        assert_eq!(compute_tree_height(31), 5);
    }

    #[test]
    fn test_precompute_subtree_sizes_empty() {
        let sizes = precompute_subtree_sizes(0);
        assert_eq!(sizes.len(), 0);
    }

    #[test]
    fn test_precompute_subtree_sizes_height_1() {
        // A tree with height 1 has only the root, no recursion needed
        let sizes = precompute_subtree_sizes(1);
        assert_eq!(sizes.len(), 0);
    }

    #[test]
    fn test_precompute_subtree_sizes_height_2() {
        // Height 2: split into upper(1) + lower(1)
        // upper_size = 2^1 - 1 = 1, lower_size = 2^1 - 1 = 1
        let sizes = precompute_subtree_sizes(2);
        assert_eq!(sizes.len(), 1);
        assert_eq!(sizes[0].upper_size, 1);
        assert_eq!(sizes[0].lower_size, 1);
    }

    #[test]
    fn test_precompute_subtree_sizes_height_3() {
        // Height 3: split into upper(2) + lower(1), then upper recursion ends at height 2
        let sizes = precompute_subtree_sizes(3);
        // First level: h=3, lower_h=1, upper_h=2
        // upper_size = 2^2 - 1 = 3, lower_size = 2^1 - 1 = 1
        assert!(sizes.len() >= 1);
        assert_eq!(sizes[0].upper_size, 3);
        assert_eq!(sizes[0].lower_size, 1);
    }

    #[test]
    fn test_precompute_subtree_sizes_height_4() {
        // Height 4 (power of 2): split into upper(2) + lower(2)
        let sizes = precompute_subtree_sizes(4);
        assert!(sizes.len() >= 1);
        // h=4, split evenly: upper_h=2, lower_h=2
        // upper_size = 2^2 - 1 = 3, lower_size = 2^2 - 1 = 3
        assert_eq!(sizes[0].upper_size, 3);
        assert_eq!(sizes[0].lower_size, 3);

        // Second level: h=2, upper_h=1, lower_h=1
        assert!(sizes.len() >= 2);
        assert_eq!(sizes[1].upper_size, 1);
        assert_eq!(sizes[1].lower_size, 1);
    }

    #[test]
    fn test_precompute_subtree_sizes_height_8() {
        // Height 8 (power of 2): demonstrates logarithmic recursion depth
        let sizes = precompute_subtree_sizes(8);

        // First level: h=8, split evenly: upper_h=4, lower_h=4
        // upper_size = 2^4 - 1 = 15, lower_size = 2^4 - 1 = 15
        assert!(sizes.len() >= 1);
        assert_eq!(sizes[0].upper_size, 15);
        assert_eq!(sizes[0].lower_size, 15);

        // Second level: h=4, upper_h=2, lower_h=2
        assert!(sizes.len() >= 2);
        assert_eq!(sizes[1].upper_size, 3);
        assert_eq!(sizes[1].lower_size, 3);

        // Third level: h=2, upper_h=1, lower_h=1
        assert!(sizes.len() >= 3);
        assert_eq!(sizes[2].upper_size, 1);
        assert_eq!(sizes[2].lower_size, 1);
    }

    #[test]
    fn test_subtree_sizes_count_matches_expected() {
        // For power-of-2 heights, we expect log2(h) recursion levels
        // Height 2: 1 level
        assert_eq!(precompute_subtree_sizes(2).len(), 1);
        // Height 4: 2 levels (4->2->done)
        assert_eq!(precompute_subtree_sizes(4).len(), 2);
        // Height 8: 3 levels (8->4->2->done)
        assert_eq!(precompute_subtree_sizes(8).len(), 3);
        // Height 16: 4 levels (16->8->4->2->done)
        assert_eq!(precompute_subtree_sizes(16).len(), 4);
    }

    #[test]
    fn test_subtree_sizes_total_matches_tree() {
        // Verify that upper + lower subtrees can reconstruct the tree structure
        // For a complete binary tree of height h:
        // - Upper subtree has (2^upper_h - 1) nodes
        // - There are 2^upper_h leaves in upper, each pointing to a lower subtree
        // - Each lower subtree has (2^lower_h - 1) nodes
        // - Total = upper_size + 2^upper_h * lower_size = 2^h - 1

        for h in 2..=10u8 {
            let sizes = precompute_subtree_sizes(h);
            if !sizes.is_empty() {
                let s = &sizes[0];
                let upper_h = ((s.upper_size + 1) as f64).log2() as usize;
                let num_lower_subtrees = 1 << upper_h;
                let total = s.upper_size + num_lower_subtrees * s.lower_size;
                let expected_total = (1 << h) - 1;
                assert_eq!(
                    total, expected_total,
                    "For height {}: upper_size={} + {} * lower_size={} = {}, expected {}",
                    h, s.upper_size, num_lower_subtrees, s.lower_size, total, expected_total
                );
            }
        }
    }

    // === VebNavigator tests for Step 2: Implicit child navigation ===

    #[test]
    fn test_veb_navigator_at_root() {
        let nav = VebNavigator::at_root(15);
        assert_eq!(nav.position, 0);
        assert_eq!(nav.subtree_base, 0);
        assert_eq!(nav.veb_depth, 0);
        assert_eq!(nav.local_position, 0);
        assert_eq!(nav.current_subtree_size, 15);
    }

    #[test]
    fn test_veb_navigator_height_2() {
        // Height 2 tree: 3 nodes
        // vEB layout for h=2: [root, left, right] (same as standard)
        // upper_size=1 (root), lower_size=1 (each child)
        let sizes = precompute_subtree_sizes(2);
        assert_eq!(sizes.len(), 1);
        assert_eq!(sizes[0].upper_size, 1);
        assert_eq!(sizes[0].lower_size, 1);

        let node_count = 3;
        let root = VebNavigator::at_root(node_count);
        assert_eq!(root.position, 0);

        // Left child: transitions from upper (size 1) to first lower subtree
        // Layout: [0: root] [1: left] [2: right]
        let left = root.left_child(&sizes);
        assert_eq!(left.position, 1, "Left child should be at position 1");
        assert_eq!(
            left.veb_depth, 1,
            "Left child should be in deeper vEB level"
        );
        assert_eq!(left.current_subtree_size, 1, "Lower subtree has size 1");

        // Right child: transitions from upper (size 1) to second lower subtree
        let right = root.right_child(&sizes);
        assert_eq!(right.position, 2, "Right child should be at position 2");
        assert_eq!(
            right.veb_depth, 1,
            "Right child should be in deeper vEB level"
        );
    }

    #[test]
    fn test_veb_navigator_height_3() {
        // Height 3 tree: 7 nodes
        // vEB split: upper_h=2 (3 nodes), lower_h=1 (1 node each)
        // Layout: [upper: 0,1,2] [lower0: 3] [lower1: 4] [lower2: 5] [lower3: 6]
        let sizes = precompute_subtree_sizes(3);
        assert_eq!(sizes[0].upper_size, 3);
        assert_eq!(sizes[0].lower_size, 1);

        let node_count = 7;
        let root = VebNavigator::at_root(node_count);
        assert_eq!(root.position, 0);

        // Within upper subtree, standard binary tree indexing
        let left = root.left_child(&sizes);
        assert_eq!(left.position, 1, "Left child of root in upper subtree");
        assert_eq!(left.veb_depth, 0, "Still in first vEB level");

        let right = root.right_child(&sizes);
        assert_eq!(right.position, 2, "Right child of root in upper subtree");
        assert_eq!(right.veb_depth, 0, "Still in first vEB level");

        // From node 1 (left child of root), descend to lower subtrees
        // Node 1's left child has local_position 2*1+1=3, which equals upper_size=3
        // So it transitions to lower subtree at leaf_index=0
        let left_left = left.left_child(&sizes);
        assert_eq!(
            left_left.position, 3,
            "Left-left should be in first lower subtree"
        );
        assert_eq!(left_left.veb_depth, 1, "Transitioned to deeper vEB level");

        // Node 1's right child has local_position 2*1+2=4, > upper_size=3
        // leaf_index = 4 - 3 = 1, so second lower subtree
        let left_right = left.right_child(&sizes);
        assert_eq!(
            left_right.position, 4,
            "Left-right should be in second lower subtree"
        );

        // Node 2's children
        let right_left = right.left_child(&sizes);
        assert_eq!(
            right_left.position, 5,
            "Right-left should be in third lower subtree"
        );

        let right_right = right.right_child(&sizes);
        assert_eq!(
            right_right.position, 6,
            "Right-right should be in fourth lower subtree"
        );
    }

    #[test]
    fn test_veb_navigator_height_4() {
        // Height 4 tree: 15 nodes
        // vEB split: upper_h=2 (3 nodes), lower_h=2 (3 nodes each)
        // Layout: [upper: 0,1,2] [lower0: 3,4,5] [lower1: 6,7,8] [lower2: 9,10,11] [lower3: 12,13,14]
        let sizes = precompute_subtree_sizes(4);
        assert_eq!(sizes[0].upper_size, 3);
        assert_eq!(sizes[0].lower_size, 3);

        let node_count = 15;
        let root = VebNavigator::at_root(node_count);

        // Navigate within upper subtree
        let left = root.left_child(&sizes);
        assert_eq!(left.position, 1);
        let right = root.right_child(&sizes);
        assert_eq!(right.position, 2);

        // Transition to lower subtrees
        // From node 1 (local_pos=1), left child has local_pos=3, >= upper_size=3
        // leaf_index = 3 - 3 = 0, lower subtree at base = 3 + 0*3 = 3
        let left_left = left.left_child(&sizes);
        assert_eq!(
            left_left.position, 3,
            "Should be root of first lower subtree"
        );
        assert_eq!(left_left.subtree_base, 3);
        assert_eq!(left_left.veb_depth, 1);

        // Within the lower subtree, continue navigation
        // Lower subtree has sizes[1] = {upper: 1, lower: 1}
        let lll = left_left.left_child(&sizes);
        assert_eq!(lll.position, 4, "Left child within lower subtree");

        let llr = left_left.right_child(&sizes);
        assert_eq!(llr.position, 5, "Right child within lower subtree");

        // Check other lower subtrees
        let left_right = left.right_child(&sizes);
        assert_eq!(left_right.position, 6, "Root of second lower subtree");
        assert_eq!(left_right.subtree_base, 6);

        let right_left = right.left_child(&sizes);
        assert_eq!(right_left.position, 9, "Root of third lower subtree");

        let right_right = right.right_child(&sizes);
        assert_eq!(right_right.position, 12, "Root of fourth lower subtree");
    }

    #[test]
    fn test_veb_navigator_all_positions_reachable() {
        // For a complete binary tree, verify all positions are reachable via navigation
        for height in 2..=5u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let mut visited = vec![false; node_count];

            // BFS through the tree using navigation
            let mut queue = vec![VebNavigator::at_root(node_count)];
            while let Some(nav) = queue.pop() {
                if !nav.is_valid() {
                    continue;
                }
                visited[nav.position] = true;

                // Add children if they're within bounds
                let left = nav.left_child(&sizes);
                let right = nav.right_child(&sizes);

                if left.is_valid() {
                    queue.push(left);
                }
                if right.is_valid() {
                    queue.push(right);
                }
            }

            // All positions should be visited
            for (i, &v) in visited.iter().enumerate() {
                assert!(v, "Height {}: Position {} not reachable", height, i);
            }
        }
    }

    #[test]
    fn test_veb_navigator_no_duplicate_positions() {
        // Verify that left and right children are always different
        for height in 2..=5u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;

            let mut queue = vec![VebNavigator::at_root(node_count)];
            while let Some(nav) = queue.pop() {
                let left = nav.left_child(&sizes);
                let right = nav.right_child(&sizes);

                if left.is_valid() && right.is_valid() {
                    assert_ne!(
                        left.position, right.position,
                        "Height {}: Node at {} has same position for both children: {}",
                        height, nav.position, left.position
                    );
                    queue.push(left);
                    queue.push(right);
                }
            }
        }
    }

    #[test]
    fn test_veb_navigator_leaf_count() {
        // The number of leaves (nodes with children out of bounds) should be 2^(h-1)
        for height in 2..=5u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let expected_leaf_count = 1usize << (height - 1);

            let mut leaf_count = 0;
            let mut queue = vec![VebNavigator::at_root(node_count)];
            let mut visited = vec![false; node_count];

            while let Some(nav) = queue.pop() {
                if !nav.is_valid() || visited[nav.position] {
                    continue;
                }
                visited[nav.position] = true;

                let left = nav.left_child(&sizes);
                let right = nav.right_child(&sizes);

                // A leaf has both children invalid (out of subtree bounds)
                let left_invalid = !left.is_valid();
                let right_invalid = !right.is_valid();

                if left_invalid && right_invalid {
                    leaf_count += 1;
                } else {
                    // Only add children that are valid
                    if !left_invalid {
                        queue.push(left);
                    }
                    if !right_invalid {
                        queue.push(right);
                    }
                }
            }

            assert_eq!(
                leaf_count, expected_leaf_count,
                "Height {}: Expected {} leaves, found {}",
                height, expected_leaf_count, leaf_count
            );
        }
    }

    #[test]
    fn test_veb_navigator_is_valid() {
        // Test the is_valid method
        let sizes = precompute_subtree_sizes(2);
        let node_count = 3;
        let root = VebNavigator::at_root(node_count);

        // Root should be valid
        assert!(root.is_valid());

        // Children of root should be valid
        let left = root.left_child(&sizes);
        let right = root.right_child(&sizes);
        assert!(left.is_valid());
        assert!(right.is_valid());

        // Children of leaves (positions 1 and 2) should be invalid
        // since they're single-node subtrees with no children
        let left_left = left.left_child(&sizes);
        let left_right = left.right_child(&sizes);
        assert!(!left_left.is_valid(), "Child of leaf should be invalid");
        assert!(!left_right.is_valid(), "Child of leaf should be invalid");
    }

    // === Step 3 tests: Pointer-less Node and Navigator-based search ===

    #[test]
    fn test_leaf_positions_collected_in_order() {
        // Verify leaves are collected in left-to-right order
        for height in 2..=5u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let expected_leaf_count = 1usize << (height - 1);

            let leaves =
                BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes);

            assert_eq!(
                leaves.len(),
                expected_leaf_count,
                "Height {}: Expected {} leaves, found {}",
                height,
                expected_leaf_count,
                leaves.len()
            );

            // Verify all leaves are unique
            let mut sorted = leaves.clone();
            sorted.sort();
            sorted.dedup();
            assert_eq!(
                sorted.len(),
                leaves.len(),
                "Height {}: Duplicate leaf positions found",
                height
            );

            // Verify all positions are valid indices
            for &pos in &leaves {
                assert!(
                    pos < node_count,
                    "Height {}: Invalid leaf position {}",
                    height,
                    pos
                );
            }
        }
    }

    #[test]
    fn test_navigator_based_tree_traversal_matches_leaf_count() {
        // The number of leaves collected via navigator should equal 2^(h-1)
        for height in 2..=6u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let expected_leaves = 1usize << (height - 1);

            let leaves =
                BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes);

            assert_eq!(
                leaves.len(),
                expected_leaves,
                "Height {}: Navigator traversal found {} leaves, expected {}",
                height,
                leaves.len(),
                expected_leaves
            );
        }
    }

    // === Step 4 tests: update_leaf() and incremental index updates ===

    #[test]
    fn test_leaf_positions_stored_in_tree() {
        // Verify that the tree stores leaf_positions for O(1) lookup
        for height in 2..=5u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let expected_leaf_count = 1usize << (height - 1);

            let leaf_positions =
                BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes);

            assert_eq!(
                leaf_positions.len(),
                expected_leaf_count,
                "Height {}: Expected {} leaf positions",
                height,
                expected_leaf_count
            );

            // Verify leaf_positions are within bounds
            for &pos in &leaf_positions {
                assert!(
                    pos < node_count,
                    "Height {}: Leaf position {} out of bounds",
                    height,
                    pos
                );
            }
        }
    }

    #[test]
    fn test_leaf_index_to_position_mapping() {
        // Test the leaf_index_to_position mapping
        for height in 2..=4u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let leaf_positions: Box<[usize]> =
                BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                    .into_boxed_slice();

            // Create a minimal tree structure to test leaf_index_to_position
            let tree = BlockSearchTree::<u32, u32> {
                nodes: (0..node_count)
                    .map(|_| Node::Internal {
                        min_rhs: Key::Supremum,
                    })
                    .collect::<Vec<_>>()
                    .into_boxed_slice(),
                subtree_sizes: sizes,
                height,
                leaf_positions: leaf_positions.clone(),
            };

            // Test valid indices
            for (idx, &expected_pos) in leaf_positions.iter().enumerate() {
                let pos = tree.leaf_index_to_position(idx);
                assert_eq!(
                    pos,
                    Some(expected_pos),
                    "Height {}: leaf_index {} should map to position {}",
                    height,
                    idx,
                    expected_pos
                );
            }

            // Test out-of-bounds index
            let out_of_bounds = tree.leaf_index_to_position(leaf_positions.len());
            assert_eq!(
                out_of_bounds, None,
                "Height {}: out-of-bounds index should return None",
                height
            );
        }
    }

    #[test]
    fn test_leaf_count() {
        // Test the leaf_count method
        for height in 2..=4u8 {
            let sizes = precompute_subtree_sizes(height);
            let node_count = (1usize << height) - 1;
            let expected_leaf_count = 1usize << (height - 1);
            let leaf_positions: Box<[usize]> =
                BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                    .into_boxed_slice();

            let tree = BlockSearchTree::<u32, u32> {
                nodes: (0..node_count)
                    .map(|_| Node::Internal {
                        min_rhs: Key::Supremum,
                    })
                    .collect::<Vec<_>>()
                    .into_boxed_slice(),
                subtree_sizes: sizes,
                height,
                leaf_positions,
            };

            assert_eq!(
                tree.leaf_count(),
                expected_leaf_count,
                "Height {}: Expected {} leaves",
                height,
                expected_leaf_count
            );
        }
    }

    #[test]
    fn test_update_leaf_basic() {
        // Test basic update_leaf functionality
        // Create a height-3 tree (7 nodes, 4 leaves)
        let height = 3u8;
        let sizes = precompute_subtree_sizes(height);
        let node_count = 7;
        let leaf_positions: Box<[usize]> =
            BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                .into_boxed_slice();

        // Create nodes - mark leaf positions as Leaf nodes
        let mut nodes: Vec<Node<u32, u32>> = (0..node_count)
            .map(|_| Node::Internal {
                min_rhs: Key::Supremum,
            })
            .collect();

        // Convert leaf positions to actual Leaf nodes
        for &pos in leaf_positions.iter() {
            nodes[pos] = Node::Leaf(
                Key::Supremum,
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            );
        }

        let mut tree = BlockSearchTree::<u32, u32> {
            nodes: nodes.into_boxed_slice(),
            subtree_sizes: sizes,
            height,
            leaf_positions,
        };

        // Update leaf 0 with a new key
        let success = tree.update_leaf(0, Key::Value(10));
        assert!(success, "update_leaf should succeed for valid leaf index");

        // Verify the leaf was updated
        let leaf_pos = tree.leaf_index_to_position(0).unwrap();
        match &tree.nodes[leaf_pos] {
            Node::Leaf(key, _) => {
                assert_eq!(*key, Key::Value(10), "Leaf key should be updated to 10");
            }
            _ => panic!("Expected Leaf node at position {}", leaf_pos),
        }

        // Update leaf 2 with a different key
        let success = tree.update_leaf(2, Key::Value(30));
        assert!(success, "update_leaf should succeed for leaf index 2");

        let leaf_pos = tree.leaf_index_to_position(2).unwrap();
        match &tree.nodes[leaf_pos] {
            Node::Leaf(key, _) => {
                assert_eq!(*key, Key::Value(30), "Leaf key should be updated to 30");
            }
            _ => panic!("Expected Leaf node at position {}", leaf_pos),
        }
    }

    #[test]
    fn test_update_leaf_out_of_bounds() {
        // Test that update_leaf returns false for out-of-bounds index
        let height = 2u8;
        let sizes = precompute_subtree_sizes(height);
        let node_count = 3;
        let leaf_positions: Box<[usize]> =
            BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                .into_boxed_slice();

        // Create nodes
        let mut nodes: Vec<Node<u32, u32>> = (0..node_count)
            .map(|_| Node::Internal {
                min_rhs: Key::Supremum,
            })
            .collect();

        for &pos in leaf_positions.iter() {
            nodes[pos] = Node::Leaf(
                Key::Supremum,
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            );
        }

        let mut tree = BlockSearchTree::<u32, u32> {
            nodes: nodes.into_boxed_slice(),
            subtree_sizes: sizes,
            height,
            leaf_positions,
        };

        // Try to update a non-existent leaf
        let success = tree.update_leaf(100, Key::Value(999));
        assert!(!success, "update_leaf should fail for out-of-bounds index");
    }

    #[test]
    fn test_update_leaf_with_supremum() {
        // Test updating a leaf with Key::Supremum
        let height = 2u8;
        let sizes = precompute_subtree_sizes(height);
        let node_count = 3;
        let leaf_positions: Box<[usize]> =
            BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                .into_boxed_slice();

        let mut nodes: Vec<Node<u32, u32>> = (0..node_count)
            .map(|_| Node::Internal {
                min_rhs: Key::Supremum,
            })
            .collect();

        for &pos in leaf_positions.iter() {
            nodes[pos] = Node::Leaf(
                Key::Value(50),
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            );
        }

        let mut tree = BlockSearchTree::<u32, u32> {
            nodes: nodes.into_boxed_slice(),
            subtree_sizes: sizes,
            height,
            leaf_positions,
        };

        // Update to Supremum (representing an empty block)
        let success = tree.update_leaf(0, Key::Supremum);
        assert!(success, "update_leaf should succeed with Supremum");

        let leaf_pos = tree.leaf_index_to_position(0).unwrap();
        match &tree.nodes[leaf_pos] {
            Node::Leaf(key, _) => {
                assert_eq!(*key, Key::Supremum, "Leaf key should be Supremum");
            }
            _ => panic!("Expected Leaf node"),
        }
    }

    #[test]
    fn test_propagate_key_change_updates_ancestors() {
        // Test that propagate_key_change updates internal node min_rhs values
        // Create a height-3 tree (7 nodes, 4 leaves)
        // In-order leaves: positions [3, 4, 5, 6] for height-3 vEB layout
        let height = 3u8;
        let sizes = precompute_subtree_sizes(height);
        let node_count = 7;
        let leaf_positions: Box<[usize]> =
            BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                .into_boxed_slice();

        // Set up internal nodes with initial min_rhs values
        // For a height-3 tree:
        // - Node 0 (root): min_rhs points to leaf 2 (third leaf, first of right subtree)
        // - Node 1: min_rhs points to leaf 1 (second leaf)
        // - Node 2: min_rhs points to leaf 3 (fourth leaf)
        let nodes: Vec<Node<u32, u32>> = vec![
            Node::Internal {
                min_rhs: Key::Value(30),
            }, // root, min_rhs = min of right subtree
            Node::Internal {
                min_rhs: Key::Value(20),
            }, // left child
            Node::Internal {
                min_rhs: Key::Value(40),
            }, // right child
            Node::Leaf(
                Key::Value(10),
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            ), // leaf 0
            Node::Leaf(
                Key::Value(20),
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            ), // leaf 1
            Node::Leaf(
                Key::Value(30),
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            ), // leaf 2
            Node::Leaf(
                Key::Value(40),
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            ), // leaf 3
        ];

        let mut tree = BlockSearchTree::<u32, u32> {
            nodes: nodes.into_boxed_slice(),
            subtree_sizes: sizes,
            height,
            leaf_positions,
        };

        // Update leaf 2 (first leaf of root's right subtree) to a new value
        // This should update the root's min_rhs
        tree.update_leaf(2, Key::Value(35));

        // Verify root's min_rhs was updated
        match &tree.nodes[0] {
            Node::Internal { min_rhs } => {
                assert_eq!(
                    *min_rhs,
                    Key::Value(35),
                    "Root's min_rhs should be updated to 35"
                );
            }
            _ => panic!("Expected Internal node at root"),
        }

        // Node 2 (right child of root) should also be updated since leaf 2
        // is the first leaf of its left subtree - wait, that means node 2's
        // min_rhs shouldn't change (it points to its right subtree's min)
        // Let me verify the actual structure...
    }

    #[test]
    fn test_update_all_leaves_sequentially() {
        // Test updating all leaves in sequence
        let height = 3u8;
        let sizes = precompute_subtree_sizes(height);
        let node_count = 7;
        let leaf_positions: Box<[usize]> =
            BlockSearchTree::<u32, u32>::collect_leaf_positions_inorder(node_count, &sizes)
                .into_boxed_slice();
        let leaf_count = leaf_positions.len();

        let mut nodes: Vec<Node<u32, u32>> = (0..node_count)
            .map(|_| Node::Internal {
                min_rhs: Key::Supremum,
            })
            .collect();

        for &pos in leaf_positions.iter() {
            nodes[pos] = Node::Leaf(
                Key::Supremum,
                Block {
                    cell_slice_ptr: std::ptr::null(),
                    length: 0,
                },
            );
        }

        let mut tree = BlockSearchTree::<u32, u32> {
            nodes: nodes.into_boxed_slice(),
            subtree_sizes: sizes,
            height,
            leaf_positions,
        };

        // Update each leaf with a unique key
        for i in 0..leaf_count {
            let key = (i as u32 + 1) * 10;
            let success = tree.update_leaf(i, Key::Value(key));
            assert!(success, "update_leaf should succeed for leaf {}", i);

            // Verify the update
            let pos = tree.leaf_index_to_position(i).unwrap();
            match &tree.nodes[pos] {
                Node::Leaf(k, _) => {
                    assert_eq!(*k, Key::Value(key), "Leaf {} should have key {}", i, key);
                }
                _ => panic!("Expected Leaf at position {}", pos),
            }
        }
    }

    // === Step 5 tests: RebalanceResult and affected block computation ===

    #[test]
    fn test_rebalance_result_new() {
        let result = RebalanceResult::new(2..5);
        assert_eq!(result.affected_blocks, 2..5);
        assert!(result.has_affected_blocks());
    }

    #[test]
    fn test_rebalance_result_none() {
        let result = RebalanceResult::none();
        assert_eq!(result.affected_blocks, 0..0);
        assert!(!result.has_affected_blocks());
    }

    #[test]
    fn test_rebalance_result_has_affected_blocks() {
        // Empty range should return false
        let empty = RebalanceResult::new(0..0);
        assert!(!empty.has_affected_blocks());

        let empty2 = RebalanceResult::new(5..5);
        assert!(!empty2.has_affected_blocks());

        // Non-empty range should return true
        let non_empty = RebalanceResult::new(0..1);
        assert!(non_empty.has_affected_blocks());

        let non_empty2 = RebalanceResult::new(3..10);
        assert!(non_empty2.has_affected_blocks());
    }

    #[test]
    fn test_rebalance_result_equality() {
        let r1 = RebalanceResult::new(1..5);
        let r2 = RebalanceResult::new(1..5);
        let r3 = RebalanceResult::new(2..5);

        assert_eq!(r1, r2);
        assert_ne!(r1, r3);
    }

    #[test]
    fn test_rebalance_result_debug() {
        let result = RebalanceResult::new(2..4);
        let debug_str = format!("{:?}", result);
        assert!(debug_str.contains("RebalanceResult"));
        assert!(debug_str.contains("affected_blocks"));
    }

    #[test]
    fn test_rebalance_result_clone() {
        let original = RebalanceResult::new(5..10);
        let cloned = original.clone();
        assert_eq!(original, cloned);
    }

    // === Step 7 tests: Incremental index updates wired into insert ===

    #[test]
    fn test_block_index_update_leaf_delegates_to_tree() {
        // Test that BlockIndex::update_leaf properly delegates to BlockSearchTree
        let capacity = 16usize;
        let pma = PackedMemoryArray::<Cell<u32, u32>>::with_capacity(capacity);
        let data = Arc::new(pma);

        let mut index = BTreeMap::generate_index(Arc::clone(&data));

        // The tree should have leaves, try to update one
        let leaf_count = index.index_tree.leaf_count();
        if leaf_count > 0 {
            let success = index.update_leaf(0, Key::Value(42));
            assert!(success, "update_leaf should succeed for valid leaf index");

            // Verify the update took effect
            let pos = index.index_tree.leaf_index_to_position(0).unwrap();
            match &index.index_tree.nodes[pos] {
                Node::Leaf(k, _) => {
                    assert_eq!(*k, Key::Value(42), "Leaf should have updated key");
                }
                _ => panic!("Expected Leaf node"),
            }
        }
    }

    #[test]
    fn test_block_index_update_leaf_out_of_bounds() {
        let capacity = 16usize;
        let pma = PackedMemoryArray::<Cell<u32, u32>>::with_capacity(capacity);
        let data = Arc::new(pma);

        let mut index = BTreeMap::generate_index(Arc::clone(&data));

        // Try to update a leaf that doesn't exist
        let success = index.update_leaf(9999, Key::Value(42));
        assert!(!success, "update_leaf should fail for out-of-bounds index");
    }

    #[test]
    fn test_block_index_slot_size() {
        let capacity = 16usize;
        let pma = PackedMemoryArray::<Cell<u32, u32>>::with_capacity(capacity);
        let data = Arc::new(pma);

        let index = BTreeMap::generate_index(Arc::clone(&data));

        // slot_size = log2(requested_capacity) = log2(16) = 4
        assert_eq!(index.slot_size(), 4);
    }

    #[test]
    fn test_block_index_compute_block_min_key_empty_block() {
        let capacity = 16usize;
        let pma = PackedMemoryArray::<Cell<u32, u32>>::with_capacity(capacity);
        let data = Arc::new(pma);

        let index = BTreeMap::generate_index(Arc::clone(&data));

        // Empty PMA should have Key::Supremum for all blocks
        let min_key = index.compute_block_min_key(0);
        assert_eq!(min_key, Key::Supremum);
    }

    #[test]
    fn test_block_index_compute_block_min_key_out_of_bounds() {
        let capacity = 16usize;
        let pma = PackedMemoryArray::<Cell<u32, u32>>::with_capacity(capacity);
        let data = Arc::new(pma);

        let index = BTreeMap::generate_index(Arc::clone(&data));

        // Block index way out of bounds should return Supremum
        let min_key = index.compute_block_min_key(9999);
        assert_eq!(min_key, Key::Supremum);
    }

    #[test]
    fn test_update_index_for_affected_blocks_empty() {
        // When there are no affected blocks, update should be a no-op
        let mut btree: BTreeMap<u32, u32> = BTreeMap::new(16);

        // Call with empty vectors - should not panic
        btree.update_index_for_affected_blocks(&[], None);
    }

    #[test]
    fn test_insert_updates_index_synchronously() {
        // Test that insert immediately updates the index (no 50ms delay)
        let mut btree: BTreeMap<u32, u32> = BTreeMap::new(16);

        // Insert a value
        btree.insert(10, 100);

        // Immediately check if we can get the value back
        // This tests that the index was updated synchronously
        let result = btree.get(&10);
        assert_eq!(
            result,
            Some(100),
            "Value should be retrievable immediately after insert"
        );
    }

    #[test]
    fn test_insert_multiple_values_index_stays_consistent() {
        // Test that multiple inserts maintain a consistent index
        // Use a small capacity similar to the working integration tests
        let mut btree: BTreeMap<u8, u8> = BTreeMap::new(16);

        // Insert several values (ascending order first to match add_ordered_values pattern)
        btree.insert(3, 30);
        btree.insert(8, 80);
        btree.insert(12, 120);

        // All values should be retrievable immediately
        assert_eq!(btree.get(&3), Some(30));
        assert_eq!(btree.get(&8), Some(80));
        assert_eq!(btree.get(&12), Some(120));

        // Non-existent key should return None
        assert_eq!(btree.get(&7), None);
    }

    #[test]
    fn test_insert_updates_index_without_delay() {
        // Verify that inserts complete quickly (no INDEX_UPDATE_DELAY)
        use std::time::Instant;

        let start = Instant::now();
        let mut btree: BTreeMap<u32, u32> = BTreeMap::new(16);

        // Insert a few values
        for i in 0..5 {
            btree.insert(i, i * 10);
        }

        let elapsed = start.elapsed();

        // Should complete much faster than the old 50ms delay per insert
        // Allow generous margin for slow CI systems, but it should definitely be < 50ms
        assert!(
            elapsed.as_millis() < 50,
            "Inserts should complete quickly without INDEX_UPDATE_DELAY, took {}ms",
            elapsed.as_millis()
        );

        // Verify all values are retrievable
        for i in 0..5 {
            assert_eq!(btree.get(&i), Some(i * 10));
        }
    }

    #[test]
    fn test_insert_uses_direct_pointer_iteration() {
        // Test that insert works correctly with direct pointer iteration
        // by inserting values that would span multiple blocks
        let mut btree: BTreeMap<u32, u32> = BTreeMap::new(32);

        // Insert values in reverse order to exercise the rebalancing logic
        for i in (0..20).rev() {
            btree.insert(i, i * 100);
        }

        // All values should be retrievable
        for i in 0..20 {
            assert_eq!(btree.get(&i), Some(i * 100), "Failed to retrieve key {}", i);
        }
    }

    #[test]
    fn test_insert_middle_of_block_with_direct_iteration() {
        // Test inserting values in the middle of existing data
        // Use same pattern as add_unordered_values which is known to work
        let mut btree: BTreeMap<u8, u8> = BTreeMap::new(16);

        // Insert a few values in non-sequential order (same as add_unordered_values)
        btree.insert(5, 50);
        btree.insert(3, 30);
        btree.insert(2, 20);

        // All values should be retrievable
        assert_eq!(btree.get(&5), Some(50));
        assert_eq!(btree.get(&3), Some(30));
        assert_eq!(btree.get(&2), Some(20));
    }

    #[test]
    fn test_cell_iterator_direct_construction() {
        // Test that CellIterator can be constructed directly from a pointer
        // and iterates correctly
        use super::super::cell::CellIterator;

        let pma: PackedMemoryArray<Cell<u32, u32>> = PackedMemoryArray::with_capacity(16);

        // Get the start and end pointers from the active range
        let start_ptr = pma.active_range.start;
        let end_ptr = pma.active_range.end;

        // Create iterator directly from pointers
        let iter: CellIterator<u32, u32> = CellIterator::new(start_ptr, end_ptr);

        // Should be able to iterate through the cells
        let count = iter.count();
        assert!(
            count > 0,
            "CellIterator should iterate over at least some cells"
        );
    }

    #[test]
    fn test_rebalance_with_direct_iteration() {
        // Test that rebalance works correctly with direct pointer iteration
        // by forcing multiple rebalances through sequential inserts
        let mut btree: BTreeMap<u32, u32> = BTreeMap::new(16);

        // Insert enough values to trigger rebalancing
        for i in 0..15 {
            btree.insert(i, i);
        }

        // All values should still be retrievable after rebalancing
        for i in 0..15 {
            assert_eq!(
                btree.get(&i),
                Some(i),
                "Value lost after rebalancing for key {}",
                i
            );
        }
    }

    /// Test that verifies insert time scales as O(log N) rather than O(N).
    ///
    /// After the fix to replace skip_while() with direct CellIterator construction,
    /// insert operations should have roughly constant time regardless of tree size,
    /// rather than growing linearly with the number of elements.
    ///
    /// This test creates trees of increasing sizes and measures insert timing.
    /// If the fix is correct, the ratio of insert times should be roughly constant
    /// (within a reasonable factor), not growing proportionally with size.
    #[test]
    fn test_insert_scaling_is_sublinear() {
        use std::time::Instant;

        // Test at two different sizes to verify scaling
        let small_size = 100;
        let large_size = 1000;
        let num_inserts = 50; // More inserts for more stable timing

        // Measure insert time for small tree
        let mut small_tree: BTreeMap<usize, usize> = BTreeMap::new(small_size + num_inserts);
        for i in 0..small_size {
            small_tree.insert(i * 2, i); // Even numbers
        }

        let small_start = Instant::now();
        for i in 0..num_inserts {
            small_tree.insert(i * 2 + 1, i); // Odd numbers (new inserts)
        }
        let small_elapsed = small_start.elapsed();

        // Measure insert time for large tree
        let mut large_tree: BTreeMap<usize, usize> = BTreeMap::new(large_size + num_inserts);
        for i in 0..large_size {
            large_tree.insert(i * 2, i);
        }

        let large_start = Instant::now();
        for i in 0..num_inserts {
            large_tree.insert(i * 2 + 1, i);
        }
        let large_elapsed = large_start.elapsed();

        // Calculate the ratio of times
        // With O(N) complexity: ratio should be ~10x (1000/100)
        // With O(log N) complexity: ratio should be ~1.5x (log2(1000)/log2(100)  10/6.6)
        // In practice, with cache effects and constant factors, we allow up to 3x
        // This is still significantly better than the 10x expected for O(N)
        let ratio = large_elapsed.as_nanos() as f64 / small_elapsed.as_nanos().max(1) as f64;

        // Allow up to 8x ratio to account for measurement noise, cache effects, and debug mode
        // If it were truly O(N), we'd expect ~10x, so 3x is an agressive threshold
        // The key insight is that we should NOT see 10x scaling
        assert!(
            ratio < 3.0,
            "Insert time scaled too much with size: {:.2}x (expected <8x for sublinear behavior). \
             Small tree ({} elements): {:?}, Large tree ({} elements): {:?}",
            ratio,
            small_size,
            small_elapsed,
            large_size,
            large_elapsed
        );

        // Verify correctness - all values should be retrievable
        for i in 0..num_inserts {
            assert_eq!(
                small_tree.get(&(i * 2 + 1)),
                Some(i),
                "Small tree missing inserted key"
            );
            assert_eq!(
                large_tree.get(&(i * 2 + 1)),
                Some(i),
                "Large tree missing inserted key"
            );
        }
    }
}
